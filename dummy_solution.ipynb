{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import Bounds\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(\n",
    "    style='whitegrid', # стиль figure\n",
    "    font_scale=2, # размер шрифта\n",
    "    rc={'lines.linewidth': 3, # ширина линий\n",
    "        'text.usetex' : True} # использовать tex\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import read_data, normalization, plot_results\n",
    "from opt_utils import func, fit_curve \n",
    "from opt_utils import f_standard, get_x0_standard, unpack_standard\n",
    "from opt_utils import f_exp, get_x0_exp, unpack_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_standard = Bounds(\n",
    "    np.array([0, 0, 0, 0, 0, 0], dtype=np.float64), \n",
    "    np.array([np.inf, np.inf, np.inf, np.inf, np.inf, np.inf], dtype=np.float64)\n",
    "#     [0, 0, 0, 0, 0, 0],\n",
    "#     [None, None, None, None, None, None]\n",
    ")\n",
    "\n",
    "# from scipy.optimize import LinearConstraint\n",
    "# linear_constraint = LinearConstraint([[1, 1, 1, 0, 0, 0], \n",
    "#                                       [0, 0, 0, 1, -1, 0]], \n",
    "#                                      [1, 1], \n",
    "#                                      [0, np.inf])\n",
    "\n",
    "cons_standard = [\n",
    "    {\n",
    "        'type': 'eq',\n",
    "        'fun': lambda x: np.array([x[0] + x[1] + x[2] - 1]),\n",
    "        'jac': lambda x: np.array([1.0, 1.0, 1.0, 0, 0, 0])\n",
    "    },\n",
    "    {\n",
    "        'type': 'ineq',\n",
    "        'fun': lambda x: np.array([x[3] - x[4]]),\n",
    "        'jac': lambda x: np.array([0, 0, 0, 1.0, -1.0, 0])\n",
    "    },\n",
    "]\n",
    "\n",
    "bounds_exp = Bounds(\n",
    "    np.array([0, 0], dtype=np.float64), \n",
    "    np.array([np.inf, np.inf], dtype=np.float64)\n",
    ")\n",
    "\n",
    "cons_exp = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Собираем все дериктории стеков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = 'soil_CFs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(source_path) if not d.endswith('.png')]\n",
    "results = []\n",
    "# for cdir in ['5', '13']: \n",
    "#     dirs.remove(cdir)\n",
    "#     dirs.extend([os.path.join(cdir, d) for d in os.listdir(os.path.join(source_path, cdir))])\n",
    "# dirs.remove('.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CF11_NN',\n",
       " 'CF11',\n",
       " 'CF9_NN',\n",
       " 'CF12_NN',\n",
       " 'REV1_1_NN',\n",
       " 'CF3',\n",
       " 'REV1_1',\n",
       " 'CF12',\n",
       " 'CF14_NN',\n",
       " 'CF9',\n",
       " 'REV2_1',\n",
       " 'REV2_1_NN',\n",
       " 'CF3_NN',\n",
       " 'CF14']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_name in dirs:\n",
    "    data_path = os.path.join(source_path, dir_name) \n",
    "    data = read_data(data_path)\n",
    "    \n",
    "    dir_path = os.path.join(data_path, 'results')\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "    print('Current directory: {}'.format(dir_path))\n",
    "    \n",
    "    # Добавим в данные корр функции, усредненные по всем направлениям\n",
    "    mean_data = dict()\n",
    "    for tag, v in data.items():\n",
    "        tag_edited = tag[:-1]\n",
    "        if tag_edited not in mean_data:\n",
    "            mean_data[tag_edited] = np.array(v)\n",
    "        else:\n",
    "            mean_data[tag_edited] += np.array(v)\n",
    "    for tag, v in mean_data.items():\n",
    "        mean_data[tag] = list(v / 3)\n",
    "    data.update(mean_data)\n",
    "    \n",
    "    # Для каждого тега сделаем фит\n",
    "    for tag in tqdm(data):\n",
    "        phi = data[tag][0] \n",
    "        exp_data = normalization(data, tag=tag)\n",
    "        n = exp_data.shape[0]\n",
    "\n",
    "        scores = dict()\n",
    "        # Семплируем много стартовых точек, чтобы получить наилучшее решение\n",
    "        for i in range(50):\n",
    "            # Два способа зафитить кривую - чисто экспоненциальный или две экспоненты + квадратичное слагаемое\n",
    "#             if tag.startswith('L2'):\n",
    "#                 result = fit_curve(exp_data, f_exp, get_x0_exp, \n",
    "#                                    unpack_exp, \n",
    "#                                    bounds_exp, \n",
    "#                                    cons_exp, \n",
    "#                                    phi=phi\n",
    "#                                   )\n",
    "#             else:\n",
    "            result = fit_curve(exp_data, f_standard, get_x0_standard,\n",
    "                               unpack_standard, \n",
    "                               bounds_standard, \n",
    "                               cons_standard\n",
    "                              )\n",
    "            if result['success']:\n",
    "                scores[result['SSE']] = result\n",
    "\n",
    "        best = min(scores) \n",
    "        result = scores[best]\n",
    "        result['tag'] = tag\n",
    "        result['dir_name'] = dir_name\n",
    "        labels_mapping = {\n",
    "            'fitted': 'Fitted',\n",
    "            'exp_data': 'Data'\n",
    "        }\n",
    "        plot_results(\n",
    "            result, \n",
    "            labels_mapping=labels_mapping,\n",
    "            tag=tag, \n",
    "            dir_path=dir_path\n",
    "        )\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(\n",
    "        result, \n",
    "        ax, \n",
    "        labels_mapping=None, \n",
    "        labels=None, \n",
    "        tag=None, \n",
    "        x_up=1, \n",
    "        x_down=-0.1, \n",
    "        dpi=400\n",
    "):\n",
    "    if labels is None:\n",
    "        labels = ['fitted', 'exp_data']\n",
    "    \n",
    "    xlim = 0\n",
    "    for label in labels:\n",
    "        y = result[label]\n",
    "        r = np.arange(0, len(y))\n",
    "        xlim = max(xlim, len(y))\n",
    "        label = label if labels_mapping is None else labels_mapping[label]\n",
    "        ax.plot(r, y, label=label)\n",
    "    # plt.plot(r, z, label='Data S2')\n",
    "#     plt.plot(r, y, label='Fitted')\n",
    "    ax.legend(loc='best')\n",
    "    if tag is not None:\n",
    "        ax.set_title(r'${corr_func}_{{ {direction} }}$'.format(corr_func=tag[0], direction=tag[1:]))\n",
    "    ax.set_ylim([x_down, x_up])\n",
    "    ax.set_xlim([0, xlim])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_params(ax, result):\n",
    "    ys = [0.05, 0.23, 0.41, 0.59, 0.77, 0.95]\n",
    "    seq = ['a', 'b', 'c', 'a1', 'a2', 'a3'][::-1]\n",
    "    result = unpack_standard(result['x'])\n",
    "    for y, k in zip(ys, seq):\n",
    "        v = result[k]\n",
    "        if (len(k) > 1):\n",
    "            k = k[0] + '_' + k[1:]\n",
    "        s = r'${} = {:.4f}$'.format(k, v)\n",
    "        ax.text(0.25, y, s, fontsize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks_mapping = {\n",
    "    '1' : '1', \n",
    "    '10' : '2', \n",
    "    '11' : '3', \n",
    "    '12' : '4', \n",
    "    '13/down' : '5', \n",
    "    '13/upper' : '6',\n",
    "    '14' : '7', \n",
    "    '2' : '8', \n",
    "    '3' : '9', \n",
    "    '4' : '10', \n",
    "    '5/down_part900' : '11',\n",
    "    '5/upper_part900' : '12', \n",
    "    '6' : '13', \n",
    "    '7' : '14', \n",
    "    '8' : '15', \n",
    "    '9'  : '16'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['C2', 'L2', 'S2', 'SS2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks = list(stacks_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results = {r['tag']: r \n",
    "                    for r in results \n",
    "                    if (r['dir_name'] == stack)} # and (r['tag'][-1] in ['X', 'Y', 'Z'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C2',\n",
       " 'C2X',\n",
       " 'C2Y',\n",
       " 'C2Z',\n",
       " 'L2',\n",
       " 'L2X',\n",
       " 'L2Y',\n",
       " 'L2Z',\n",
       " 'S2',\n",
       " 'S2X',\n",
       " 'S2Y',\n",
       " 'S2Z',\n",
       " 'SS2',\n",
       " 'SS2X',\n",
       " 'SS2Y',\n",
       " 'SS2Z']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = sorted(filtered_results.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for stack in stacks:\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(40, 100))\n",
    "\n",
    "    gs = fig.add_gridspec(2 + 2 * len(tags), 4)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0:2, 0:2])\n",
    "    img=mpimg.imread('CFs/sample{}.png'.format(stacks_mapping[stack]))\n",
    "    ax.axis('off')\n",
    "    ax.imshow(img)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0:2, 2:4])\n",
    "    for k in keys:\n",
    "        x = filtered_results[k]['exp_data']\n",
    "        ax.plot(np.arange(len(x)), x, '--', label=k)        \n",
    "    ax.legend(loc='best')\n",
    "\n",
    "    shift = 2\n",
    "\n",
    "    for i, tag in enumerate(tags):\n",
    "        for j, suff in enumerate(['', 'X', 'Y', 'Z']):\n",
    "            ax = fig.add_subplot(gs[shift+0+2*i:shift+1+2*i, 0+j:1+j])\n",
    "            plot_results(filtered_results[tag + suff], ax, tag=tag + suff, labels_mapping=labels_mapping)\n",
    "\n",
    "            ax = fig.add_subplot(gs[shift+1+2*i:shift+2+2*i, 0+j:1+j])\n",
    "            print_params(ax, filtered_results[tag + suff])\n",
    "            ax.axis('off')\n",
    "\n",
    "#     plt.show()\n",
    "    plt.savefig('compiled/{}.png'.format(stacks_mapping[stack]))\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSEs = {(stacks_mapping[r['dir_name']], r['tag']): r['SSE'] for r in results if r['tag'][-1] not in ['X', 'Y', 'Z']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('13', 'C2'), 0.02299206915591812),\n",
       " (('10', 'C2'), 0.022144128460825606),\n",
       " (('4', 'C2'), 0.021127634252452183),\n",
       " (('15', 'C2'), 0.021122430317305107),\n",
       " (('10', 'S2'), 0.018049298170469973),\n",
       " (('1', 'SS2'), 0.01657650159821126),\n",
       " (('8', 'SS2'), 0.016317642613046062),\n",
       " (('11', 'C2'), 0.015982738666142415),\n",
       " (('8', 'C2'), 0.015764876337991177),\n",
       " (('15', 'SS2'), 0.014660279943899516),\n",
       " (('2', 'SS2'), 0.013949518755376733),\n",
       " (('10', 'SS2'), 0.013937972029981078),\n",
       " (('9', 'SS2'), 0.013861118602478366),\n",
       " (('9', 'C2'), 0.013825565154590245),\n",
       " (('14', 'C2'), 0.012986915230810811),\n",
       " (('8', 'S2'), 0.012665226676725927),\n",
       " (('13', 'SS2'), 0.012196824622479011),\n",
       " (('14', 'SS2'), 0.011377122465037802),\n",
       " (('4', 'SS2'), 0.011283205504484022),\n",
       " (('11', 'SS2'), 0.010829711680256638),\n",
       " (('3', 'SS2'), 0.010810325888442643),\n",
       " (('12', 'S2'), 0.009420375605373938),\n",
       " (('1', 'C2'), 0.008328899161403287),\n",
       " (('3', 'C2'), 0.0077380356212790585),\n",
       " (('7', 'SS2'), 0.00739048645759463),\n",
       " (('16', 'SS2'), 0.0071566116405117775),\n",
       " (('13', 'S2'), 0.006866402531533184),\n",
       " (('3', 'S2'), 0.005343539589858191),\n",
       " (('2', 'S2'), 0.004890341172020437),\n",
       " (('4', 'S2'), 0.004017621542357169),\n",
       " (('2', 'C2'), 0.0037310682048589264),\n",
       " (('7', 'C2'), 0.0035937473952053498),\n",
       " (('16', 'C2'), 0.0034300061719067677),\n",
       " (('14', 'S2'), 0.002885138963714876),\n",
       " (('7', 'S2'), 0.0026516248896127654),\n",
       " (('1', 'S2'), 0.0026070895696621386),\n",
       " (('15', 'S2'), 0.0024981727918658055),\n",
       " (('11', 'S2'), 0.001552698435217256),\n",
       " (('1', 'L2'), 0.0014169429935928226),\n",
       " (('16', 'S2'), 0.0012721956771493184),\n",
       " (('7', 'L2'), 0.0010380547678287867),\n",
       " (('13', 'L2'), 0.0009667571542745906),\n",
       " (('2', 'L2'), 0.0009528769696989786),\n",
       " (('9', 'S2'), 0.0009054874265716807),\n",
       " (('11', 'L2'), 0.0008730797104879954),\n",
       " (('14', 'L2'), 0.0008598661097844219),\n",
       " (('4', 'L2'), 0.000693357524506194),\n",
       " (('10', 'L2'), 0.0006039845294054259),\n",
       " (('15', 'L2'), 0.0005745092657519644),\n",
       " (('3', 'L2'), 0.0003783651090286863),\n",
       " (('16', 'L2'), 0.0003760672668474033),\n",
       " (('9', 'L2'), 0.00033845545008496624),\n",
       " (('8', 'L2'), 0.0003242473459422489)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(SSEs.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for r in results:\n",
    "    X.append(np.array(r['x']).reshape(1, -1))\n",
    "    Y.append('{}_{}'.format(r['dir_name'], r['tag']))\n",
    "X = np.concatenate(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('viz_data_new.pkl', 'wb') as f:\n",
    "    pickle.dump((X, Y), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_new.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
